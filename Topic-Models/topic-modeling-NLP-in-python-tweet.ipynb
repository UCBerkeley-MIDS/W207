{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Topic Modeling and Natural Language Processing with Twitter Data\n",
    "\n",
    "##  Jason Anastasopoulos\n",
    "##  December 4, 2018\n",
    "### Email: ljanastas@uga.edu\n",
    "\n",
    "The code below provides a brief introduction on acquiring Twitter data using the twitter API via Python. For this exercise I will be acquiring Donald Trump's tweets and will try to figure out what the topics his tweets are using the Latent Dirichlet Allocation  Topic Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os,re,csv\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from stop_words import get_stop_words\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import numpy as np\n",
    "import scipy\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.plotly as py\n",
    "import twitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we enter our Twitter credentials. These can be acquired through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Fri Dec 19 19:38:51 +0000 2008\", \"description\": \"Microsoft Visiting Professor @PrincetonCITP\\u25aa\\ufe0fAssistant Professor @UGA_PA_Policy & Political Science \\u25aa\\ufe0f political economy\\u25aa\\ufe0f machine learning\\u25aa\\ufe0f causal inference\", \"favourites_count\": 1108, \"followers_count\": 581, \"friends_count\": 502, \"geo_enabled\": true, \"id\": 18249358, \"id_str\": \"18249358\", \"lang\": \"en\", \"listed_count\": 33, \"location\": \"Athens, GA\", \"name\": \"Jason Anastasopoulos\", \"profile_background_color\": \"C0DEED\", \"profile_background_image_url\": \"http://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_background_image_url_https\": \"https://abs.twimg.com/images/themes/theme1/bg.png\", \"profile_banner_url\": \"https://pbs.twimg.com/profile_banners/18249358/1535050189\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/1065001203887570944/5hA3pVIK_normal.jpg\", \"profile_image_url_https\": \"https://pbs.twimg.com/profile_images/1065001203887570944/5hA3pVIK_normal.jpg\", \"profile_link_color\": \"F9F7F7\", \"profile_sidebar_border_color\": \"C0DEED\", \"profile_sidebar_fill_color\": \"DDEEF6\", \"profile_text_color\": \"333333\", \"profile_use_background_image\": true, \"screen_name\": \"jlanastas\", \"status\": {\"created_at\": \"Tue Nov 27 20:40:30 +0000 2018\", \"favorited\": true, \"id\": 1067518549684563968, \"id_str\": \"1067518549684563968\", \"lang\": \"en\", \"retweet_count\": 41, \"retweeted\": true, \"retweeted_status\": {\"created_at\": \"Tue Nov 27 14:48:43 +0000 2018\", \"favorite_count\": 349, \"favorited\": true, \"id\": 1067430021529096193, \"id_str\": \"1067430021529096193\", \"lang\": \"en\", \"retweet_count\": 41, \"retweeted\": true, \"source\": \"<a href=\\\"https://mobile.twitter.com\\\" rel=\\\"nofollow\\\">Twitter Lite</a>\", \"text\": \"Mockingly subtweeting students is a poor form of teaching.\\n\\nMockingly subtweeting students is usually self-promotio\\u2026 https://t.co/rJQsFKsW6M\", \"truncated\": true}, \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"RT @JohnHolbein1: Mockingly subtweeting students is a poor form of teaching.\\n\\nMockingly subtweeting students is usually self-promotional.\\u2026\"}, \"statuses_count\": 894, \"url\": \"https://t.co/fBLr6MzlyV\"}\n"
     ]
    }
   ],
   "source": [
    "api = twitter.Api(consumer_key='',\n",
    "                      consumer_secret='',\n",
    "                      access_token_key='',\n",
    "                      access_token_secret='')\n",
    "\n",
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search the Twitter API using keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1070149834643070976, u'Giuliani Releases Statement on Flynn Sentencing: It\\'s Like \"Spitting on a Sidewalk\" ...and Mueller Team \"Are Sick P\\u2026 https://t.co/iJXHDoCTn4')\n",
      "(1070012903544250373, u'My friend in Germany sent me a picture of his latest litter of German shepherd puppies to see if I would like one f\\u2026 https://t.co/MeM7naOII0')\n",
      "(1070075275184984064, u'RT if you think puppies are cute.\\n\\n#ProBowlVote\\n\\n@LarryFitzgerald\\n@P2\\n@chanjones55\\n@DavidJohnson31\\n@AndyLee4\\u2026 https://t.co/jiYM7CTpYw')\n",
      "(1070483211778703360, u'Free Dog \\u276f\\u276f https://t.co/gkGrlupOI9 \\u276e\\u276e #Dogs #Puppies #DogFinder #AdoptADog https://t.co/FxOMeZBttK')\n",
      "(1070483185975185408, u'RT @jikooksexts: jungkook: *accidentally sends jimin a picture of 7 puppies*\\n\\njungkook: oops wrong number\\n\\njimin: wait i want one\\n\\njungkook\\u2026')\n",
      "(1070483179843153920, u'RT @Drebae_: Ursula scammed a mermaid out of her voice and soul &amp; then stole sis man.\\n\\nCruella De Vill wanted to skin 100 puppies \\n\\n&amp; Malef\\u2026')\n",
      "(1070483175065800705, u'RT @BuzzFeed: Sabrina Carpenter Plays With Puppies While Answering Fan Questions https://t.co/8cGQVpywsK')\n",
      "(1070483172893302786, u'Dear Puppies, I will pay you in dog biscuits every time you help me seduce a woman, deal? Sincerely, Men https://t.co/E7f7SecUuN')\n",
      "(1070483170901061633, u'RT @Drebae_: Ursula scammed a mermaid out of her voice and soul &amp; then stole sis man.\\n\\nCruella De Vill wanted to skin 100 puppies \\n\\n&amp; Malef\\u2026')\n",
      "(1070483137333882880, u'Sent a vid of puppies to my fam and lmfao my dad really said \\u201cwho says\\u201d to these women. It only took one of em to s\\u2026 https://t.co/mXGdRzuUFt')\n",
      "(1070483123144675329, u'RT @AdamBroud: [Disney Pitch Meeting]\\n\\nWriter: So kids love puppies\\n\\nExec: Haha true\\n\\nWriter: This movie is about skinning alive 101 of the\\u2026')\n",
      "(1070483121152364545, u'Humans &amp; dogs are a lot more alike than we think. We both dislike returning shopping carts. \\n\\n#cute #puppies #video https://t.co/Cu0C7RyXFi')\n",
      "(1070483112419909633, u'RT @Eunique_nx: Cruella de Vil kidnapped puppies for her clothing line bc the drip is forever https://t.co/in0eQN3ihi')\n",
      "(1070483099052634112, u'RT @Drebae_: Ursula scammed a mermaid out of her voice and soul &amp; then stole sis man.\\n\\nCruella De Vill wanted to skin 100 puppies \\n\\n&amp; Malef\\u2026')\n",
      "(1070483098054418433, u'RT @Eunique_nx: Cruella de Vil kidnapped puppies for her clothing line bc the drip is forever https://t.co/in0eQN3ihi')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = api.GetSearch(\"puppies\") # Replace happy with your search\n",
    "for tweet in search:\n",
    "    print(tweet.id, tweet.text)\n",
    "    \n",
    "len(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python twitter library has a lot of cool functions that you can use and learn about through the help() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method GetUserTimeline in module twitter.api:\n",
      "\n",
      "GetUserTimeline(self, user_id=None, screen_name=None, since_id=None, max_id=None, count=None, include_rts=True, trim_user=False, exclude_replies=False) method of twitter.api.Api instance\n",
      "    Fetch the sequence of public Status messages for a single user.\n",
      "    \n",
      "    The twitter.Api instance must be authenticated if the user is private.\n",
      "    \n",
      "    Args:\n",
      "      user_id (int, optional):\n",
      "        Specifies the ID of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid user ID\n",
      "        is also a valid screen name.\n",
      "      screen_name (str, optional):\n",
      "        Specifies the screen name of the user for whom to return the\n",
      "        user_timeline. Helpful for disambiguating when a valid screen\n",
      "        name is also a user ID.\n",
      "      since_id (int, optional):\n",
      "        Returns results with an ID greater than (that is, more recent\n",
      "        than) the specified ID. There are limits to the number of\n",
      "        Tweets which can be accessed through the API. If the limit of\n",
      "        Tweets has occurred since the since_id, the since_id will be\n",
      "        forced to the oldest ID available.\n",
      "      max_id (int, optional):\n",
      "        Returns only statuses with an ID less than (that is, older\n",
      "        than) or equal to the specified ID.\n",
      "      count (int, optional):\n",
      "        Specifies the number of statuses to retrieve. May not be\n",
      "        greater than 200.\n",
      "      include_rts (bool, optional):\n",
      "        If True, the timeline will contain native retweets (if they\n",
      "        exist) in addition to the standard stream of tweets.\n",
      "      trim_user (bool, optional):\n",
      "        If True, statuses will only contain the numerical user ID only.\n",
      "        Otherwise a full user object will be returned for each status.\n",
      "      exclude_replies (bool, optional)\n",
      "        If True, this will prevent replies from appearing in the returned\n",
      "        timeline. Using exclude_replies with the count parameter will mean you\n",
      "        will receive up-to count tweets - this is because the count parameter\n",
      "        retrieves that many tweets before filtering out retweets and replies.\n",
      "        This parameter is only supported for JSON and XML responses.\n",
      "    \n",
      "    Returns:\n",
      "      A sequence of Status instances, one for each message up to count\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(api.GetUserTimeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'RT @CLTCBerkeley: Check out this incredible research news from @BerkeleyISchool! I Schoolers developed a custom-fit earpiece that can captu\\u2026',\n",
       " u\"\\U0001f44b\\U0001f3fd Hey I School friends! Do you have a @kaggle account? Go vote for @BerkeleyData student Rob Mulla's kernal! It wo\\u2026 https://t.co/a7u2GkwYoi\",\n",
       " u'Yes! Buckland\\'s \"Information and Society\" is a concise and easy to understand intro to Information Science, and rec\\u2026 https://t.co/cmVTyPlxgq',\n",
       " u'RT @UCBStartup: The @hultprize @UCBerkeley campus round is underway! Joint @BerkeleyISchool &amp; @BerkeleyHaas   team Roadmap, pitching their\\u2026',\n",
       " u\"Did you miss the TUI Showcase Monday? It's on again today! \\n\\nStop by 202 South Hall before 11am to see and try out\\u2026 https://t.co/qLs086q8rU\",\n",
       " u'Prof Steve Weber: Trump Administration Has Elevated China\\u2019s Role in International Property Theft to a National Leve\\u2026 https://t.co/iNVbvNo8bi',\n",
       " u\"Mark you calendars! Next week alumna @kingjen will return to South Hall to present 'Privacy, Disclosure, and Social\\u2026 https://t.co/N7vks68o0f\",\n",
       " u'\\U0001f4e2 RESEARCH NEWS: I Schoolers have developed a custom-fit earpiece that that can capture #passthoughts through brain\\u2026 https://t.co/rEui7itKMW',\n",
       " u'Interested in what our students are doing with NLP?\\n\\nStop by tomorrow, 12/4, 3:30-5pm for the final project poster\\u2026 https://t.co/IAkhnGTaSD',\n",
       " u'RT @CLTCBerkeley: CLTC FD Steve Weber says the #Marriott data #breach could be the work of criminal gangs or nation state actors. \"Govts ar\\u2026']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = api.GetUserTimeline(screen_name=\"BerkeleyISchool\", count=5000)\n",
    "tweets = [i.AsDict() for i in t]\n",
    "\n",
    "tweettext = [i[\"text\"] for i in tweets]\n",
    "\n",
    "len(tweettext)\n",
    "\n",
    "tweettext[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "######## So far so good not lets clean this up ###\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "# create English stop words list\n",
    "en_stop = get_stop_words('en')\n",
    "\n",
    "# Create p_stemmer of class PorterStemmer\n",
    "p_stemmer = PorterStemmer()\n",
    "texts = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are pre-processing the text by creating a tokenizer that splits the documents up into tokens (words or phrases), creating a dictionary of stop words and creating a \"stemmer\" which stems the words (ie removing \"-ing\" endings etc. We also remove extraneous \"bill related\" words such as \"propXX_XXXX\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'cltcberkeley',\n",
       " u'check',\n",
       " u'incred',\n",
       " u'research',\n",
       " u'news',\n",
       " u'berkeleyischool',\n",
       " u'schooler',\n",
       " u'develop',\n",
       " u'custom',\n",
       " u'fit',\n",
       " u'earpiec',\n",
       " u'can',\n",
       " u'captu']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tweettext:\n",
    "    #print \"Processing\",i\n",
    "    # clean and tokenize document string\n",
    "    tokens = tokenizer.tokenize(i)\n",
    "    # remove all numbers\n",
    "    tokens = [x for x in tokens if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
    "    # remove structural words\n",
    "    tokens = [x for x in tokens if len(x) > 1]\n",
    "    tokens = [x.lower() for x in tokens]\n",
    "    tokens = [x for x in tokens if 'http' not in x]\n",
    "    tokens = [x for x in tokens if x not in \"_\"]\n",
    "    tokens = [x for x in tokens if x not in 'rt']\n",
    "    tokens = [x for x in tokens if x not in \".co\"]\n",
    "    # remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    # stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    # add tokens to list\n",
    "    texts.append(stemmed_tokens)\n",
    "\n",
    "dictionaryall = corpora.Dictionary(texts)\n",
    "\n",
    "corpusall = [dictionaryall.doc2bow(text) for text in texts]\n",
    "\n",
    "texts[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'RT @CLTCBerkeley: Check out this incredible research news from @BerkeleyISchool! I Schoolers developed a custom-fit earpiece that can captu\\u2026',\n",
       " u\"\\U0001f44b\\U0001f3fd Hey I School friends! Do you have a @kaggle account? Go vote for @BerkeleyData student Rob Mulla's kernal! It wo\\u2026 https://t.co/a7u2GkwYoi\",\n",
       " u'Yes! Buckland\\'s \"Information and Society\" is a concise and easy to understand intro to Information Science, and rec\\u2026 https://t.co/cmVTyPlxgq',\n",
       " u'RT @UCBStartup: The @hultprize @UCBerkeley campus round is underway! Joint @BerkeleyISchool &amp; @BerkeleyHaas   team Roadmap, pitching their\\u2026',\n",
       " u\"Did you miss the TUI Showcase Monday? It's on again today! \\n\\nStop by 202 South Hall before 11am to see and try out\\u2026 https://t.co/qLs086q8rU\",\n",
       " u'Prof Steve Weber: Trump Administration Has Elevated China\\u2019s Role in International Property Theft to a National Leve\\u2026 https://t.co/iNVbvNo8bi',\n",
       " u\"Mark you calendars! Next week alumna @kingjen will return to South Hall to present 'Privacy, Disclosure, and Social\\u2026 https://t.co/N7vks68o0f\",\n",
       " u'\\U0001f4e2 RESEARCH NEWS: I Schoolers have developed a custom-fit earpiece that that can capture #passthoughts through brain\\u2026 https://t.co/rEui7itKMW',\n",
       " u'Interested in what our students are doing with NLP?\\n\\nStop by tomorrow, 12/4, 3:30-5pm for the final project poster\\u2026 https://t.co/IAkhnGTaSD',\n",
       " u'RT @CLTCBerkeley: CLTC FD Steve Weber says the #Marriott data #breach could be the work of criminal gangs or nation state actors. \"Govts ar\\u2026']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweettext[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs tokenization, stop word removal and number removal and places the corpora into a clean list that will be ready for analysis using the Latent Dirichlet Allocation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Latent Dirichlet Allocation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate LDA model\n",
    "ldamodelall = gensim.models.ldamodel.LdaModel(corpusall, num_topics=3, \n",
    "                                              id2word = dictionaryall, passes=20,\n",
    "                                              minimum_probability=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above estimates a 5 topic topic model using Trump's tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, u'0.009*\"ucberkeley\" + 0.008*\"thank\" + 0.007*\"school\" + 0.007*\"student\" + 0.007*\"work\"'), (1, u'0.012*\"prof\" + 0.010*\"berkeleyischool\" + 0.010*\"ucberkeley\" + 0.010*\"student\" + 0.010*\"today\"'), (2, u'0.015*\"us\" + 0.015*\"join\" + 0.011*\"student\" + 0.011*\"amp\" + 0.010*\"today\"')]\n"
     ]
    }
   ],
   "source": [
    "print(ldamodelall.print_topics(num_topics=5, num_words=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the first 5 topics from the full model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the topic here?\n",
    "\n",
    "### Topic 1: will, great, state, want, peopl -- Label: Immigration\n",
    "### Topic 2: presid, will, trump, two, mueller -- Label: Russia Investigatons I \n",
    "### Topic 3: presid, look, bush, argentina, first  -- Label: Events \n",
    "### Topic 4: will,china,border,can,start -- Label: International Relations/Policies.\n",
    "### Topic 5: great, year, america, make, thank -- Label: Self Congratulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out the distribution over topics for a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'RT @Blum_Center: Read about @BigIdeasContest winner @Dosteducation - breaking the cycle of #illiteracy by empowering parents https://t.co/W\\u2026'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweettext[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.030524886398311704),\n",
       " (1, 0.93839353996770924),\n",
       " (2, 0.031081573633978985)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodelall[corpusall[20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breakout Session Exercise\n",
    "\n",
    "1. Collect and process all tweets from Berkeley's School of Information Account: @BerkeleyISchool.\n",
    "\n",
    "2. Estimate a 5-topic topic model and label each of the topics.\n",
    "\n",
    "3. Label one of the tweets using the topic distribution. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
